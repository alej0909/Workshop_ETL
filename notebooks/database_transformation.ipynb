{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ”„ Data Transformation\n",
    "In this notebook, we will carry out a comprehensive data transformation process to ensure that the data is structured and usable for subsequent analysis or reporting.\n",
    "\n",
    "We will load the environment variables from the .env file, which contains essential configurations such as database credentials. Then, we'll get the working directory from these variables and add it to the system path to ensure that the project's modules can be imported correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workdir:  C:/Users/Administrador/Desktop/Workshops ETL/Workshop_ETL\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "work_dir = os.getenv('WORK_DIR')\n",
    "\n",
    "sys.path.append(work_dir)\n",
    "\n",
    "print('Workdir: ', work_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will import the necessary modules and classes for the rest of the notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.db_connection import build_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import inspect\n",
    "from src.model import CandidatesTransformed\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "from src.transform_data import DataTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now establish a connection to the PostgreSQL database using the build_engine function.\n",
    "\n",
    "A SQLAlchemy session will be created using the database engine established in the previous step. This session will be used for performing read and write operations on the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to the database postgres!\n"
     ]
    }
   ],
   "source": [
    "engine = build_engine()\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will check if the CandidatesTransformed table exists in the database. If it does, the table will be dropped, and a new table will be created. This ensures that the table is up-to-date and ready to receive new data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table creation was successful.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    inspector = inspect(engine)\n",
    "\n",
    "    if inspector.has_table('CandidatesTransformed'):\n",
    "        try:\n",
    "            CandidatesTransformed.__table__.drop(engine)\n",
    "        except SQLAlchemyError as e:\n",
    "            print(f\"Error dropping table: {e}\")\n",
    "            raise\n",
    "    try:\n",
    "        CandidatesTransformed.__table__.create(engine)\n",
    "        print(\"Table creation was successful.\")\n",
    "    except SQLAlchemyError as e:\n",
    "        print(f\"Error creating table: {e}\")\n",
    "        raise\n",
    "\n",
    "except SQLAlchemyError as error:\n",
    "    print(f\"An error occurred: {error}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to perform the necessary data transformations. These transformations will include:\n",
    "\n",
    "- Generating an ID column.\n",
    "- Renaming columns for consistency.\n",
    "- Adding the Hired column based on the candidate's scores.\n",
    "- Categorizing technologies.\n",
    "- Saving the transformed data back to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transformation and upload were successful.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    transformer = DataTransformer('../data/candidates.csv')\n",
    "    \n",
    "    # Standardizing and transforming data\n",
    "    transformer.generate_ids()\n",
    "    transformer.standardize_column_names()\n",
    "    transformer.calculate_hiring_status()\n",
    "    transformer.categorize_technology()\n",
    "    \n",
    "    # Saving transformed data to the database\n",
    "    transformer.save_transformed_data(output_path='../data/candidates_transformed.csv')\n",
    "    transformer.data.to_sql('CandidatesTransformed', engine, if_exists='append', index=False)\n",
    "    print(\"Data transformation and upload were successful.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    if session:\n",
    "        session.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… Conclusion\n",
    "In this notebook, we successfully transformed the raw data by standardizing column names, generating unique IDs, adding a 'Hired' column, categorizing technologies, and uploading the transformed data to the PostgreSQL database.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_workshop1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
